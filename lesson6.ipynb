{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "lesson6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX0xVRwv6Pba"
      },
      "source": [
        "–ü—Ä–æ–≤–µ—Å—Ç–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ RNN, LSTM, GRU –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ –æ—Ç–∑—ã–≤–æ–≤ (–∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–∞–Ω—è—Ç–∏–π/–º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRtu2KiLXql6",
        "outputId": "47663835-69e3-4d15-d5ac-c1dcda39b7d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn import model_selection, preprocessing, metrics\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "import re\n",
        "import xgboost, textblob, string\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.objectives import categorical_crossentropy\n",
        "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, MaxPooling1D, GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import optimizers\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from stop_words import get_stop_words\n",
        "from string import punctuation\n",
        "from gensim.models import Word2Vec\n",
        "nltk.download(\"punkt\")\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\", category=Warning)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPK4e9uVzDQv"
      },
      "source": [
        "data = pd.read_excel('/content/drive/My Drive/–æ—Ç–∑—ã–≤—ã –∑–∞ –ª–µ—Ç–æ.xls')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPKACge6PwAd",
        "outputId": "d0b09d4d-7ae9-4ae3-832a-d21d45bb43dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Content</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>It just works!</td>\n",
              "      <td>2017-08-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>–í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...</td>\n",
              "      <td>2017-08-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>–û—Ç–ª–∏—á–Ω–æ –≤—Å–µ</td>\n",
              "      <td>2017-08-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>–°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...</td>\n",
              "      <td>2017-08-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.</td>\n",
              "      <td>2017-08-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>–í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç</td>\n",
              "      <td>2017-08-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.</td>\n",
              "      <td>2017-08-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5</td>\n",
              "      <td>–í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç</td>\n",
              "      <td>2017-08-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5</td>\n",
              "      <td>–£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º...</td>\n",
              "      <td>2017-08-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5</td>\n",
              "      <td>–û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç</td>\n",
              "      <td>2017-08-14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Rating                                            Content        Date\n",
              "0       5                                     It just works!  2017-08-14\n",
              "1       4  –í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...  2017-08-14\n",
              "2       5                                        –û—Ç–ª–∏—á–Ω–æ –≤—Å–µ  2017-08-14\n",
              "3       5  –°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...  2017-08-14\n",
              "4       5                     –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.  2017-08-14\n",
              "5       5                                –í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç  2017-08-14\n",
              "6       5                          –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.  2017-08-14\n",
              "7       5                                     –í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç  2017-08-14\n",
              "8       5  –£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º...  2017-08-14\n",
              "9       5                                  –û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç  2017-08-14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eozCaEPvUo0",
        "outputId": "fc8c4fcd-8c70-4a5a-866a-c0dd45c6ee1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "exclude = set(punctuation)\n",
        "stop_words = set(get_stop_words(\"ru\"))\n",
        "morpher = MorphAnalyzer()\n",
        "\n",
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in exclude)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(\"\\s–Ω–µ\", \"–Ω–µ\", txt)\n",
        "    txt = nltk.word_tokenize(str(txt))\n",
        "    txt = [morpher.parse(word)[0].normal_form for word in txt if word not in stop_words]\n",
        "    return \" \".join(txt)\n",
        "\n",
        "data['text'] = data['Content'].apply(preprocess_text)\n",
        "data = data[data['Rating'] != 3]\n",
        "data['target'] = data['Rating'] > 3\n",
        "data['target'] = data['target'].astype(int)\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Content</th>\n",
              "      <th>Date</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>It just works!</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>it just works</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>–í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>—Ü–µ–ª–æ–µ —É–¥–æ–±–Ω–æ–Ω–æ–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–∏–∑ –º–∏–Ω—É—Å —Ö–æ—Ç–µ—Ç—å –±–æ–ª—å...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>–û—Ç–ª–∏—á–Ω–æ –≤—Å–µ</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>–æ—Ç–ª–∏—á–Ω–æ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>–°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>–∑–∞–≤–∏—Å–∞—Ç—å 1 —Ä–∞–±–æ—Ç–∞ –∞–Ω—Ç–∏–≤–∏—Ä—É—Å —Ä–∞–Ω–µ–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>—É–¥–æ–±–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –±—ã—Å—Ç—Ä–æ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Rating  ... target\n",
              "0       5  ...      1\n",
              "1       4  ...      1\n",
              "2       5  ...      1\n",
              "3       5  ...      1\n",
              "4       5  ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwvx4_-RwFs7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['target'], test_size=0.15,\n",
        "                                                    random_state=42, stratify=data['target'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK2zujL_997j"
      },
      "source": [
        "text_corpus_train = X_train.values\n",
        "text_corpus_test = X_test.values"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT6nE2MC-ey2"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=None, \n",
        "                     filters='#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
        "                     lower = False, split = ' ')\n",
        "tokenizer.fit_on_texts(text_corpus_train)\n",
        "\n",
        "sequences_train = tokenizer.texts_to_sequences(text_corpus_train)\n",
        "sequences_test = tokenizer.texts_to_sequences(text_corpus_test)\n",
        "\n",
        "word_count = len(tokenizer.index_word) + 1\n",
        "training_length = max([len(i.split()) for i in text_corpus_train])\n",
        "\n",
        "X_train = pad_sequences(sequences_train, maxlen=training_length)\n",
        "X_test = pad_sequences(sequences_test, maxlen=training_length)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIDobiQNjzga"
      },
      "source": [
        "epochs = 15\n",
        "batch_size = 1024"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ludAbTWn_INn"
      },
      "source": [
        "y_train = y_train.values\n",
        "y_test = y_test.values"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jwVPc-K_XO1",
        "outputId": "fc1c27dc-1b1e-4d15-c3a2-42d4c3346d5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=64,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=[keras.metrics.AUC()])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "15/15 [==============================] - 3s 176ms/step - loss: 0.5419 - auc: 0.5202 - val_loss: 0.4008 - val_auc: 0.8679\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 2s 160ms/step - loss: 0.3656 - auc: 0.7597 - val_loss: 0.3137 - val_auc: 0.8813\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 2s 163ms/step - loss: 0.3007 - auc: 0.8569 - val_loss: 0.2781 - val_auc: 0.9040\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 2s 163ms/step - loss: 0.2470 - auc: 0.9103 - val_loss: 0.2481 - val_auc: 0.9214\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 2s 156ms/step - loss: 0.1981 - auc: 0.9422 - val_loss: 0.2308 - val_auc: 0.9376\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 2s 157ms/step - loss: 0.1553 - auc: 0.9668 - val_loss: 0.2150 - val_auc: 0.9480\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 3s 179ms/step - loss: 0.1173 - auc: 0.9822 - val_loss: 0.2263 - val_auc: 0.9464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnKOZ6sA96AM",
        "outputId": "98bf8eff-f215-4ce2-e32d-fa487a19f374",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2401 - auc: 0.9378\n",
            "\n",
            "\n",
            "Test score: 0.2401239424943924\n",
            "Test accuracy: 0.9378198981285095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrXBF0xcDq1z",
        "outputId": "c7734d76-170d-43cf-b241-ce09665e2b47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=64,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "\n",
        "model.add(LSTM(64, recurrent_dropout=0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=[keras.metrics.AUC()])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 7s 445ms/step - loss: 0.5663 - auc_1: 0.5760 - val_loss: 0.4147 - val_auc_1: 0.8677\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 6s 410ms/step - loss: 0.3675 - auc_1: 0.7679 - val_loss: 0.3157 - val_auc_1: 0.8962\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 6s 431ms/step - loss: 0.2901 - auc_1: 0.8876 - val_loss: 0.2647 - val_auc_1: 0.9110\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 7s 449ms/step - loss: 0.2367 - auc_1: 0.9269 - val_loss: 0.2380 - val_auc_1: 0.9280\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 6s 419ms/step - loss: 0.1908 - auc_1: 0.9542 - val_loss: 0.2157 - val_auc_1: 0.9436\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 7s 471ms/step - loss: 0.1537 - auc_1: 0.9705 - val_loss: 0.2061 - val_auc_1: 0.9498\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 7s 459ms/step - loss: 0.1255 - auc_1: 0.9802 - val_loss: 0.2093 - val_auc_1: 0.9500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT_1dovyECmH",
        "outputId": "c810509c-a7ce-4221-9134-f2bf6fdc6e95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 38ms/step - loss: 0.2404 - auc_1: 0.9390\n",
            "\n",
            "\n",
            "Test score: 0.24038635194301605\n",
            "Test accuracy: 0.938985288143158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DESrw3MIExcR",
        "outputId": "a6985f0d-72af-43e9-b72d-25aff51740d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=64,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "\n",
        "model.add(GRU(64, recurrent_dropout=0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=[keras.metrics.AUC()])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 6s 405ms/step - loss: 0.6303 - auc_2: 0.5915 - val_loss: 0.5095 - val_auc_2: 0.8839\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 5s 365ms/step - loss: 0.3908 - auc_2: 0.7208 - val_loss: 0.3218 - val_auc_2: 0.9033\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 5s 360ms/step - loss: 0.2863 - auc_2: 0.9128 - val_loss: 0.2614 - val_auc_2: 0.9183\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 6s 369ms/step - loss: 0.2198 - auc_2: 0.9436 - val_loss: 0.2324 - val_auc_2: 0.9274\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 5s 357ms/step - loss: 0.1741 - auc_2: 0.9605 - val_loss: 0.2239 - val_auc_2: 0.9372\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 5s 366ms/step - loss: 0.1419 - auc_2: 0.9732 - val_loss: 0.2146 - val_auc_2: 0.9402\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 6s 410ms/step - loss: 0.1133 - auc_2: 0.9835 - val_loss: 0.2209 - val_auc_2: 0.9436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plx12DwjFidM",
        "outputId": "fbec922b-7d09-4e70-9a4f-2bca7a3e4e31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2617 - auc_2: 0.9335\n",
            "\n",
            "\n",
            "Test score: 0.2617008686065674\n",
            "Test accuracy: 0.9335076212882996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDbnThVyJY4G"
      },
      "source": [
        "–ü—Ä–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–∏ –±–∞—Ç—á–∞, LSTM –ø–æ—Ç–∏—Ö–æ–Ω—å–∫—É –Ω–∞—á–∏–Ω–∞–µ—Ç –æ–±—Ö–æ–¥–∏—Ç—å, –Ω–æ —Å—É–¥—è –ø–æ —Ç–µ—Å—Ç—É —Ä–∞–∑–Ω–∏—Ü–∞ —É –Ω–∏—Ö –Ω–µ–±–æ–ª—å—à–∞—è"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18PWPs8UX6ib"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}