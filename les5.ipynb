{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "les5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRNrNlfDHHnk"
      },
      "source": [
        "Берем отызывы за лето (из архива с материалами или предыдущего занятия)\n",
        "1. Учим conv сеть для классификации - выбить auc выше 0.95\n",
        "2. Предобучаем word2vec и его эмбединга инициализируем сетку, как влияет на качество?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWW1CvmXH86t",
        "outputId": "d189aae9-f7e9-4966-f5c8-3231af1dcee5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn import model_selection\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Input, Embedding, Conv1D, GlobalMaxPool1D\n",
        "from keras.objectives import categorical_crossentropy\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import optimizers\n",
        "from gensim.models import Word2Vec\n",
        "nltk.download(\"punkt\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKUbWdzmH-7O"
      },
      "source": [
        "max_words = 1000\n",
        "max_len = 100\n",
        "num_classes = 3\n",
        "epochs = 20\n",
        "batch_size = 512\n",
        "print_batch_n = 100"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t6G-PoDICwH"
      },
      "source": [
        "data = pd.read_excel('/content/drive/My Drive/отзывы за лето.xls')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8jb_7TgIW4W",
        "outputId": "03af8369-14b7-47cd-e1b9-8e0d95796007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "exclude = set(punctuation)\n",
        "stop_words = set(get_stop_words(\"ru\"))\n",
        "morpher = MorphAnalyzer()\n",
        "\n",
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in exclude)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
        "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in stop_words]\n",
        "    return \" \".join(txt)\n",
        "\n",
        "# Делаем предобработку и сокращаем количество классов до 2\n",
        "data['text'] = data['Content'].apply(preprocess_text)\n",
        "data = data[data['Rating'] != 3]\n",
        "data['target'] = data['Rating'] > 3\n",
        "data['target'] = data['target'].astype(int)\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Content</th>\n",
              "      <th>Date</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>It just works!</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>it just works</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>целое удобноной приложениеиз минус хотеть боль...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>Отлично все</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>отлично</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>зависать 1 работа антивирус ранее пользоваться...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Очень удобно, работает быстро.</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>удобно работать быстро</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Rating  ... target\n",
              "0       5  ...      1\n",
              "1       4  ...      1\n",
              "2       5  ...      1\n",
              "3       5  ...      1\n",
              "4       5  ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byGPy-_1Imz_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['target'], test_size=0.2,\n",
        "                                                    random_state=13, stratify=data['target'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-XDBuYbIqYR"
      },
      "source": [
        "train_corpus = \" \".join(X_train)\n",
        "train_corpus = train_corpus.lower()\n",
        "tokens = word_tokenize(train_corpus)\n",
        "tokens_filtered = [word for word in tokens if word.isalnum()]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1kwD7EmIvv3",
        "outputId": "ea1250b4-9813-4e27-98fa-6bf46eff82d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dist = FreqDist(tokens_filtered)\n",
        "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]\n",
        "tokens_filtered_top[:20]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['приложение',\n",
              " 'удобно',\n",
              " 'работать',\n",
              " 'удобный',\n",
              " 'отлично',\n",
              " 'нравиться',\n",
              " 'отличный',\n",
              " 'хороший',\n",
              " 'телефон',\n",
              " 'супер',\n",
              " 'быстро',\n",
              " 'мочь',\n",
              " 'обновление',\n",
              " 'пользоваться',\n",
              " 'банк',\n",
              " 'антивирус',\n",
              " 'устраивать',\n",
              " 'сбербанк',\n",
              " 'пароль',\n",
              " 'карта']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdApeQfqI0r6",
        "outputId": "cacd2212-07cd-4b00-cff4-43c93db0d049",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(tokens_filtered_top)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "699"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4MRdmTiI3av"
      },
      "source": [
        "\n",
        "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ytVS1SkI5pv"
      },
      "source": [
        "def text_to_sequence(text, maxlen):\n",
        "    result = []\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
        "    for word in tokens_filtered:\n",
        "        if word in vocabulary:\n",
        "            result.append(vocabulary[word])\n",
        "    padding = [0]*(maxlen-len(result))\n",
        "    return padding + result[-maxlen:]\n",
        "\n",
        "\n",
        "x_train = np.asarray([text_to_sequence(text, max_len) for text in X_train], dtype=np.int32)\n",
        "x_test = np.asarray([text_to_sequence(text, max_len) for text in X_test], dtype=np.int32)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo5SH1NzJAe3",
        "outputId": "8d404305-c3f6-4f7e-94be-b717734c1064",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "num_classes = 2\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
        "model.add(Conv1D(128, 3))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(10))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=[keras.metrics.AUC()])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.4828 - auc: 0.8626 - val_loss: 0.3962 - val_auc: 0.9550\n",
            "Epoch 2/20\n",
            "28/28 [==============================] - 10s 348ms/step - loss: 0.3173 - auc: 0.9528 - val_loss: 0.2536 - val_auc: 0.9661\n",
            "Epoch 3/20\n",
            "28/28 [==============================] - 10s 346ms/step - loss: 0.2112 - auc: 0.9747 - val_loss: 0.1976 - val_auc: 0.9764\n",
            "Epoch 4/20\n",
            "28/28 [==============================] - 10s 346ms/step - loss: 0.1726 - auc: 0.9817 - val_loss: 0.1881 - val_auc: 0.9783\n",
            "Epoch 5/20\n",
            "28/28 [==============================] - 10s 348ms/step - loss: 0.1592 - auc: 0.9843 - val_loss: 0.1921 - val_auc: 0.9784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8VpHhMQJXfa",
        "outputId": "1a1489f2-236f-4d3f-c491-794243ca9eb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
        "\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 1s 87ms/step - loss: 0.1755 - auc: 0.9814\n",
            "Test score: 0.17552632093429565\n",
            "Test accuracy: 0.9814278483390808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q42QejUbKDRQ"
      },
      "source": [
        "data['text_tekens'] = data['text'].apply(word_tokenize)\n",
        "\n",
        "w2v_model = Word2Vec(data['text_tekens'], size=128, window=5, min_count=1, workers=8)\n",
        "w2v_model.train(data['text_tekens'], total_examples=data['text_tekens'].shape[0], epochs=20)\n",
        "\n",
        "\n",
        "DIM = w2v_model.vector_size\n",
        "NUM = len(tokens_filtered_top) + 1\n",
        "# Инициализируем матрицу embedding слоя нулями\n",
        "embedding_matrix = np.zeros((NUM, DIM))\n",
        "# Добавляем NUM наиболее часто встречающихся слов из обучающей выборки в embedding слой\n",
        "for item in vocabulary.items():\n",
        "    if item[1] >= NUM:\n",
        "        break\n",
        "    if item[0] in w2v_model.wv.vocab.keys():\n",
        "        embedding_matrix[item[1]] = w2v_model.wv[item[0]]\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "# Сначала замораживаем веса слоя\n",
        "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len, weights=[embedding_matrix], trainable=False))\n",
        "model.add(Conv1D(128, 3))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(10))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoUsnOzqKdnl",
        "outputId": "b923ea9c-c08f-45de-bef0-d4e89108eb66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=[keras.metrics.AUC()])\n",
        "\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "28/28 [==============================] - 7s 268ms/step - loss: 0.3600 - auc_1: 0.9283 - val_loss: 0.2817 - val_auc_1: 0.9530\n",
            "Epoch 2/20\n",
            "28/28 [==============================] - 7s 258ms/step - loss: 0.2457 - auc_1: 0.9636 - val_loss: 0.2439 - val_auc_1: 0.9648\n",
            "Epoch 3/20\n",
            "28/28 [==============================] - 7s 258ms/step - loss: 0.2216 - auc_1: 0.9706 - val_loss: 0.2307 - val_auc_1: 0.9682\n",
            "Epoch 4/20\n",
            "28/28 [==============================] - 7s 258ms/step - loss: 0.2047 - auc_1: 0.9754 - val_loss: 0.2177 - val_auc_1: 0.9716\n",
            "Epoch 5/20\n",
            "28/28 [==============================] - 7s 257ms/step - loss: 0.1925 - auc_1: 0.9784 - val_loss: 0.2080 - val_auc_1: 0.9743\n",
            "Epoch 6/20\n",
            "28/28 [==============================] - 7s 257ms/step - loss: 0.1790 - auc_1: 0.9817 - val_loss: 0.2020 - val_auc_1: 0.9748\n",
            "Epoch 7/20\n",
            "28/28 [==============================] - 7s 257ms/step - loss: 0.1724 - auc_1: 0.9825 - val_loss: 0.1968 - val_auc_1: 0.9764\n",
            "Epoch 8/20\n",
            "28/28 [==============================] - 7s 257ms/step - loss: 0.1630 - auc_1: 0.9843 - val_loss: 0.1972 - val_auc_1: 0.9760\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcig8M7nKhAH",
        "outputId": "f8d7254c-97a0-487f-e40f-c4fe9870a357",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
        "\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 1s 83ms/step - loss: 0.1891 - auc_1: 0.9779\n",
            "Test score: 0.18906031548976898\n",
            "Test accuracy: 0.9779139757156372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvrqcsRTKj1M",
        "outputId": "694c0f62-c5f4-44c4-f0fb-87ace64da94c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# Размораживаем Embedding слой и дообучаем сеть\n",
        "model.layers[1].trainable = True\n",
        "adam = optimizers.Adam(lr=0.0001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=[keras.metrics.AUC()])\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 128)          89600     \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 98, 128)           49280     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 98, 128)           0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 22        \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 140,192\n",
            "Trainable params: 50,592\n",
            "Non-trainable params: 89,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed3njS5HKpvs",
        "outputId": "e927c63e-8946-4022-a48e-69ccfcf19b7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "28/28 [==============================] - 8s 270ms/step - loss: 0.1538 - auc_2: 0.9861 - val_loss: 0.1948 - val_auc_2: 0.9766\n",
            "Epoch 2/20\n",
            "28/28 [==============================] - 7s 262ms/step - loss: 0.1515 - auc_2: 0.9865 - val_loss: 0.1938 - val_auc_2: 0.9768\n",
            "Epoch 3/20\n",
            "28/28 [==============================] - 7s 257ms/step - loss: 0.1500 - auc_2: 0.9869 - val_loss: 0.1940 - val_auc_2: 0.9768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf35lQtqKqWl",
        "outputId": "498cc67a-6993-4000-990d-4b688bb9f13d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 1s 84ms/step - loss: 0.1844 - auc_2: 0.9789\n",
            "\n",
            "\n",
            "Test score: 0.1843503713607788\n",
            "Test accuracy: 0.9789301156997681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaYXjxZvNWVV"
      },
      "source": [
        "есть небольшое улучшение"
      ]
    }
  ]
}